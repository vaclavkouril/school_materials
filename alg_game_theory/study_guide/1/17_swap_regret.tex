\subsection{Lítost z výměny}
\begin{definition}\label{def:internal_regret}
Vnitřní lítost je situace, kde si hráč může posloupnost online akcí tím, že zamění všechny výskyty akce $i$ za akci $j$. 
\end{definition}
\begin{definition}\label{def:swap_regret}
    Rozšířením vnitřní lítosti \ref{def:internal_regret} je lítost z výmněny (swap regret), tedy nějaké zobrazení $X \rightarrow X$ 

    Máme-li $L^T_A = \sum^T_{t=1} l_A^t$ je ztráta $A$, kde $l^t_A = \sum^N_{i=1} p_i^t l_i^t$ tedy ztráta $A$ v kroku $t$. 

    Máme modifikační pravidlo $\mathcal{F}: X \rightarrow X$ tak pak modifikovaná posloupnost $(f^t)^T_{t=1} = (F(p^t))^T_{t=1}$, kde $f^t = (f_1^t, \dots, f_N^t)$ a $f^t_i = \sum_{j: F(j) = i} p_j^t$. 
    Pak $L^T_{A,\mathcal{F}} = \sum_{t=1}^T \sum_{i=1}^N f_i^t l_i^t$. 
\end{definition}

\begin{theorem}\label{thm:swap_max_NR}
Pro každý algoritmus $R$-externí ztráty existuje online algoritmus $M=M(A)$, takový že pro každou funkci $F: A \rightarrow A$ a $t \in \N$ platí 
\[
    L^T_M \leq L^T_{M,F} + NR.
\]
Tedy lítost z výmněny u $M$ je maximálně $NR$. 
\end{theorem}
\begin{proof}[Důkaz věty \ref{thm:swap_max_NR}]
    $M$ zkonstruujeme z $N$ kopií $A$, tak že v každém $t$ kroku $A_i$ vrátí pravděpodobnostní distribuci $q_i^t = (q^t_{i,1}, q^t_{i,2}, \dots, q^t_{i,N})$, kde $q^t_{i,j}$ je zlomkem, který $A_i$ přiřadí akci $x \in X$. 
    Zkonstruujeme pravděpodobnostní distribuci $p^t = (p^t_1, p^t_2, \dots, p^t_N)$, tím že necháme $p^t_j = \sum^N_{i=1} p^t_i q^t_{i,j}$ pro $\forall j \in X$. 
    Tedy $(p^t)^T = (p^t)^T Q^t$, kde $Q^t$ je $N\times N$ matice, kde $(Q^t)_{i,j} = q^t_{i,j}$. 
    Interpretujeme-li $Q^t$ jako matici přechodu Markovova řetězce, tak $p^t$ je stacionární distribuce. 
    Volba $p^t$ tedy dovoluje interpretaci výběru akce $j\in X$ buď že je přímo vybraná s pravděpodobností $p^t_j$ a nebo nejdříve vybereme algoritmus $A_i$ s pravděpodobností $p^t_i$ a pak vybereme $j$ s pravděpodobností $q^t_{i,j}$. 

    Jakmile dostane vektor ztráty $l^t$, tak pro každé $i \in X$ máme $p_i^tl^t$ pro algoritmus $A_i$. 
    $A_i$ pak má ztrátu $(p^t_i l^t)q^t_i$ na kroku $t$. 
    Protože je $R$-ztrátový algoritmus $A_i$ tak pro každou akci $j \in X$ máme
    \[
        \sum^T_{t=1} p_i^t (q_i^t l^t) \leq \sum_{t=1}^T p_i^T l_j^t + R.
    \]
    Sečteme-li všechny ztráty algoritmů $A_i$ v kroce $t$, na akcích $i \in X$ pak máme $\sum^N_{i=1} p_i^t(q_i^t l^t) = (p^t)^T Q^t l^t$. 
    Tedy celková ztráta na kroku $t$ je díky výběru $p^t$; $p^t \cdot l^t$. 

    Sečteme-li vše přes akce $i \in X$, tak levá strana je $L^T_M$ a protože pravá strana platí pro všechna $j \in X$ tak platí i pro libovolnou funkci $F: X\rightarrow X$
    \[
        L_M^T \leq \sum^N_{i=1} \sum^T_{t=1} p_i^t l^t_{F(i)} + N\cdot R \leq L^T_{M,F} + N\cdot R 
    \]
\end{proof}
\begin{theorem}[Důsledek \ref{thm:swap_max_NR} a \ref{thm:poly_weights}]
\label{thm:swap_poly}
Existuje online algoritmus \ref{def:online_alg} $A$, takový že pro každou $F: X \rightarrow X$ a $T \in \N$, máme 
\[
    L^T_A \leq L^T_{A,F} + O(N \sqrt{T\log N}). 
\]
\end{theorem}


\begin{algorithm}
    \floatname{algorithm}{Algoritmus}
    \algrenewcommand\algorithmicrequire{\textbf{Vstup: }}
    \algrenewcommand\algorithmicensure{\textbf{Výstup: }}
    \caption{Dynamika bez lítosti ze změny (No-swap-regret dynamics)}
    \label{alg:no_swap}
    \begin{algorithmic}[1]
        \Require Hra v normální formě \ref{def:normal_form_loss} $G= (P,A,C)$, $T\in \N$ a $\epsilon >0$
        \Ensure Pravděpodobnostní distribuce $p^t_i$ na $A_i$ pro každé $t \in \{1,2,\dots, T\}$ a $i \in P$ 
        \For{$t \in 1,2,\dots, T$}
            \State Každy hráč si zvolí nezávisle smíšenou strategii $p^t_i$ pomocí algoritmu který má lítost z výmněny maximálně \ref{def:swap_regret} $\epsilon$ s akcemi odpovídajícím čistým strategiím \ref{def:pure_strategy}
            \State Každý hráč dostane vektor ztráty $l^t_i = (l_i^t(a_i))_{a_i \in A_i}$, kde $l^t_i(a_i) \leftarrow \E[a_{-i}^t \sim p_{-i}^t]{C_i(a_i;a^t_{-i})}$
            \State $p^t_{-i} = \prod_{j \neq i} p_j^t$
        \EndFor
        \State vrátíme $\{p^t: t\in \{1,2,\dots,T\}\}$
    \end{algorithmic}
\end{algorithm}

\begin{theorem}\label{thm:avg_cce}
Mějeme hru $G=(P,A,C)$, daný parametr $\epsilon > 0$ a $T = T(\epsilon) \in \N$. Předpokládejme že po $T$ krocích dynamiky bez lítosti ze změny \ref{alg:no_swap} tak každý hráč má časově-průměrnou ztrátu maximálně $\epsilon$. 
Nechť $p^t =\sum_i^n p^t_i$ a $p = \frac{1}{T} \sum^T_{i=1} p^t$ je pruměrem z pravděpodobnostní distribuce výsledků. Pak $p$ je $\epsilon$-korelované ekvilibrium \ref{def:correlated_equiv}. Tedy je  
\[
    \E[a \sim p]{C_i(a)} \leq \E[a\sim p]{C_i(F(a_i);a_{-i})}
\]
pro každého hráče a libovolnou $F: A_i \rightarrow A_i$ funkci.
\end{theorem}
\begin{proof}[Důkaz věty \ref{thm:avg_cce}]
    Z definice $p$ a libovolného $F: A_i \rightarrow A_i$ máme 
    \[
        \E[a \sim p]{C_i(a)} = \frac{1}{T} \sum^T_{t=1} \E[a\sim p^t]{C_i(a)}
    \]
    a také
    \[
        \E[a \sim p]{C_i(F(a):a_{-i})} = \frac{1}{T} \sum^T_{t=1} \E[a\sim p^t]{C_i(F(a):a_{-i}}.
    \]

    Vzhledem k tomu, že každý hráč má průměrně v čase ztrátu maximálně $\epsilon$ a pravé strany znamenají průměr v čase očekávaných ztrát a druhá znamená hraní ne tak příznivé akce $F(a_i)$ místo $a_i$ tak máme
    \[
         \frac{1}{T} \sum^T_{t=1} \E[a\sim p^t]{C_i(a)} \leq \frac{1}{T} \sum^T_{t=1} \E[a\sim p^t]{C_i(a_i':a_{-i}} + \epsilon  
    \]
    což je definice $\epsilon$-korelovaného ekvilibria pro $p = \frac{1}{T} \sum^T_{t=1} p^t$. 
\end{proof}
